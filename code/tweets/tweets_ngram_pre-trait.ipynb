{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "Ngram_range : (1, 1)\n",
      "  Perceptron classifier : 0.7118\n",
      "  Logistic Regression classifier : 0.7871\n",
      "  naive_bayes classifier : 0.7692\n",
      "---------------\n",
      "Ngram_range : (1, 2)\n",
      "  Perceptron classifier : 0.7587\n",
      "  Logistic Regression classifier : 0.8025\n",
      "  naive_bayes classifier : 0.7853\n",
      "---------------\n",
      "Ngram_range : (1, 3)\n",
      "  Perceptron classifier : 0.7771\n",
      "  Logistic Regression classifier : 0.8023\n",
      "  naive_bayes classifier : 0.7883\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import feature_extraction\n",
    "\n",
    "\n",
    "df_chunk=pd.read_csv(\"french_tweets.csv\",chunksize=10000)\n",
    "res_chunk=[]\n",
    "for chunk in df_chunk:\n",
    "    res_chunk.append(chunk)\n",
    "    data_tweet=pd.concat(res_chunk)\n",
    "y = data_tweet[\"label\"]    \n",
    "\n",
    "liste_classifieurs= [\n",
    "    [\"Perceptron\", Perceptron(eta0=0.1, random_state=0)],\n",
    "    [\"Logistic Regression\", LogisticRegression()],\n",
    "    [\"naive_bayes\", MultinomialNB()] \n",
    "]\n",
    "en_minuscules,enlever_stopwords  = False, False\n",
    "for min_N in range(1, 2):\n",
    "  for max_N in range(min_N, 4):\n",
    "    V = CountVectorizer(ngram_range = (min_N, max_N))\n",
    "    X = V.fit_transform(data_tweet[\"text\"])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "    print( \"-\" * 15)\n",
    "    print(f\"Ngram_range : ({min_N}, {max_N})\")\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    for nom, algo in liste_classifieurs:\n",
    "        expe = str([nom, min_N, max_N, enlever_stopwords, en_minuscules])\n",
    "        clf = algo.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        print('  %s classifier : %.4f'%(nom, score))\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2681\n",
      "2.3465\n",
      "2.3677\n"
     ]
    }
   ],
   "source": [
    "print(0.7118+0.7871+0.7692)\n",
    "print(0.7587+0.8025+0.7853)\n",
    "print(0.7771+0.8023+0.7883)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser lâ€™unigramme, le bigramme et le trigramme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords False, Minuscules : False\n",
      "  Perceptron classifier : 0.6465\n",
      "  Logistic Regression classifier : 0.5391\n",
      "  naive_bayes classifier : 0.6462\n",
      "Stopwords False, Minuscules : True\n",
      "  Perceptron classifier : 0.6313\n",
      "  Logistic Regression classifier : 0.5429\n",
      "  naive_bayes classifier : 0.6588\n",
      "Stopwords True, Minuscules : False\n",
      "  Perceptron classifier : 0.6465\n",
      "  Logistic Regression classifier : 0.5551\n",
      "  naive_bayes classifier : 0.6222\n",
      "Stopwords True, Minuscules : True\n",
      "  Perceptron classifier : 0.5926\n",
      "  Logistic Regression classifier : 0.5561\n",
      "  naive_bayes classifier : 0.6335\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "min_N, max_N = 1, 3\n",
    "\n",
    "for enlever_stopwords in [False, True]:\n",
    "  liste_stopwords = None\n",
    "  if enlever_stopwords==True:\n",
    "    liste_stopwords = stopwords.words('french')\n",
    "    \n",
    "  for en_minuscules in [False, True]:\n",
    "    print(f\"Stopwords {enlever_stopwords}, Minuscules : {en_minuscules}\")\n",
    "    for max_F in [100]:\n",
    "        V = CountVectorizer(lowercase = en_minuscules, stop_words =  liste_stopwords, max_features = max_F )\n",
    "        X = V.fit_transform(data_tweet[\"text\"])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "        for nom, algo in liste_classifieurs:\n",
    "            clf = algo.fit(X_train, y_train)\n",
    "            expe = str([nom, min_N, max_N, enlever_stopwords, en_minuscules, max_F])\n",
    "            print('  %s classifier : %.4f'%(nom, score))\n",
    "            score = clf.score(X_test, y_test)\n",
    "                \n",
    "print(\"-\"*20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8317999999999999\n",
      "1.833\n",
      "1.8237999999999999\n",
      "1.7822\n"
     ]
    }
   ],
   "source": [
    "print(0.6465+0.5391+0.6462)\n",
    "print(0.6313+0.5429+0.6588)\n",
    "print(0.6465+0.5551+0.6222)\n",
    "print(0.5926+0.5561+0.6335)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "le meilleur cas : Stopwords False, Minuscules : True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
